{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcax6VI89GXtg2d1UdiaPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KozhevnikovAlexandr/OTALA-/blob/main/training%20neural%20network%20cat-vs-dog%20via%20VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ5fY4U0MVxn"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import SGD\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "from keras import losses\n",
        "import os\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi2qS-O4yVWX"
      },
      "source": [
        "# Каталог с данными для обучения\n",
        "train_dir = '/root/train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = '/root/test'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = '/root/val'\n",
        "# Размеры изображения\n",
        "img_width, img_height = 150, 150\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "# backend Tensorflow, channels_last\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Размер мини-выборки\n",
        "batch_size = 64\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 10000\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 1000\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 1000\n",
        "#Количество эпох\n",
        "epochs_count = 5\n",
        "#Количество нейронов на полносвязном слое\n",
        "dense_count = 512"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kntjJan-PBNF"
      },
      "source": [
        "#каталоги и файлы для подключения к kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F90hTvyWOB0Y"
      },
      "source": [
        "#сохранение токена пользователья kaggle\n",
        "api_token = {\"username\":\"kozhevnikovalexandr\",\"key\":\"1d2cd622e8b03a7dad939fcc90b811ab\"}\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anMVuVHnOdhN"
      },
      "source": [
        "#загрузка данных из kaggle\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91VXpla8QEiB"
      },
      "source": [
        "#распаковка файлов\n",
        "!mkdir ~/unzipped\n",
        "!unzip train.zip -d ~/unzipped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enMqgZZmvVwg"
      },
      "source": [
        "#функция для копирования части изображений в другой каталог\n",
        "def copy_images(start_index, end_index, source_dir, dest_dir):\n",
        "    for i in range(start_index, end_index):\n",
        "        shutil.copy2(os.path.join(source_dir, \"cat.\" + str(i) + \".jpg\"), \n",
        "                    os.path.join(dest_dir, \"cats\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"dog.\" + str(i) + \".jpg\"), \n",
        "                   os.path.join(dest_dir, \"dogs\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40EW_Pm8wTuI"
      },
      "source": [
        "#создание каталогов для хранения данных\n",
        "!mkdir ~/train\n",
        "!mkdir ~/train/cats\n",
        "!mkdir ~/train/dogs\n",
        "!mkdir ~/test\n",
        "!mkdir ~/test/cats\n",
        "!mkdir ~/test/dogs\n",
        "!mkdir ~/val\n",
        "!mkdir ~/val/cats\n",
        "!mkdir ~/val/dogs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmLoZPmcwmYf"
      },
      "source": [
        "#распределение по нужным каталогам\n",
        "copy_images(1, 10000, '/root/unzipped/train', train_dir)\n",
        "copy_images(10000, 11000, '/root/unzipped/train', val_dir)\n",
        "copy_images(11000, 12000, '/root/unzipped/train', test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2ZQGRcaybEG"
      },
      "source": [
        "#инициализация готовой части сети\n",
        "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "#отключение обучения уже обученной части\n",
        "vgg16_net.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhaOnazJye7J"
      },
      "source": [
        " #создание модели, \n",
        " #добавление полносвязных слоев для классификации по выделенным признакам\n",
        "  model = Sequential()\n",
        "  model.add(vgg16_net)\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(dense_count))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bOqQeCzyg0U"
      },
      "source": [
        "#компиляция модели\n",
        "#фунуция ошибок - среднекватратичная \n",
        "#оптимизатор Adam\n",
        "model.compile(loss=losses.mean_squared_error,\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLVvh170y1_g"
      },
      "source": [
        "#создание генератора, помещаем все пиксели изображения в диапазон от 0 до 255\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTOIfGohy2bG",
        "outputId": "ef836c1d-5837-4674-9bcd-cf4d765d7832"
      },
      "source": [
        "#генератор данных для обучения\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19998 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urJPZ0STy3aW",
        "outputId": "876297e7-5f60-4ec1-f835-8ce0f8699260"
      },
      "source": [
        "#генератор данных для проверки\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kJSc5GZy3gf",
        "outputId": "608236e7-860d-466d-a4e8-221b6733f3ed"
      },
      "source": [
        "#генератор данных для тестиования\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RpdOhxFy5sZ",
        "outputId": "b75993ef-e9b2-4848-d941-542b90c6b4d6"
      },
      "source": [
        "#обучение модели\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs_count,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "156/156 [==============================] - 2078s 13s/step - loss: 0.2473 - accuracy: 0.5907 - val_loss: 0.1355 - val_accuracy: 0.8188\n",
            "Epoch 2/10\n",
            "156/156 [==============================] - 2075s 13s/step - loss: 0.1405 - accuracy: 0.7992 - val_loss: 0.1071 - val_accuracy: 0.8583\n",
            "Epoch 3/10\n",
            "156/156 [==============================] - 2074s 13s/step - loss: 0.1155 - accuracy: 0.8385 - val_loss: 0.0965 - val_accuracy: 0.8729\n",
            "Epoch 4/10\n",
            "156/156 [==============================] - 2100s 13s/step - loss: 0.1037 - accuracy: 0.8581 - val_loss: 0.0899 - val_accuracy: 0.8833\n",
            "Epoch 5/10\n",
            "156/156 [==============================] - 2098s 13s/step - loss: 0.0969 - accuracy: 0.8662 - val_loss: 0.0876 - val_accuracy: 0.8854\n",
            "Epoch 6/10\n",
            "156/156 [==============================] - 2093s 13s/step - loss: 0.0907 - accuracy: 0.8798 - val_loss: 0.0845 - val_accuracy: 0.8844\n",
            "Epoch 7/10\n",
            "156/156 [==============================] - 2084s 13s/step - loss: 0.0861 - accuracy: 0.8853 - val_loss: 0.0843 - val_accuracy: 0.8917\n",
            "Epoch 8/10\n",
            "156/156 [==============================] - 2082s 13s/step - loss: 0.0809 - accuracy: 0.8926 - val_loss: 0.0824 - val_accuracy: 0.8875\n",
            "Epoch 9/10\n",
            "156/156 [==============================] - 2088s 13s/step - loss: 0.0798 - accuracy: 0.8941 - val_loss: 0.0781 - val_accuracy: 0.8844\n",
            "Epoch 10/10\n",
            "156/156 [==============================] - 2089s 13s/step - loss: 0.0794 - accuracy: 0.8923 - val_loss: 0.0804 - val_accuracy: 0.8938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff3e3ebfd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHD6_jQNy7uk"
      },
      "source": [
        "#оценка работы на генераторе для тестиования\n",
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnsF-WIwy8bM"
      },
      "source": [
        "print(\"Точность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}